# ðŸ‡¸ðŸ‡¦ Arabic Sentiment Analysis using BERT

This project uses a pre-trained BERT model to classify Arabic tweets into **Positive**, **Neutral**, or **Negative** sentiments.

---

## Summary

- Preprocessed Arabic tweets (cleaned text).
- Used CAMeL-Lab BERT model for direct sentiment prediction.
- Dropped original labels and predicted new ones.
- Visualized results and saved output to CSV.


## Used Tools

- Python (Google Colab)
- HuggingFace Transformers
- Pandas, NLTK, Emoji
- Seaborn, Matplotlib


## Output

- Cleaned text + predicted sentiment (CSV).
- Bar chart of sentiment distribution.


## Model

[CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment](https://huggingface.co/CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment)

## Data 
https://www.kaggle.com/code/yasmeenhany/arabic-sentiment-analysis-using-arabic-bert

